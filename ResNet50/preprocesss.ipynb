{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dpreprocess.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"UkBnEnaxKL9N"},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Input\n","import argparse\n","import os\n","from tensorflow.keras.applications import ResNet50V2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyWp9U1gKPlc","executionInfo":{"status":"ok","timestamp":1619273993538,"user_tz":-180,"elapsed":2064343,"user":{"displayName":"Deep Team","photoUrl":"","userId":"13688180598913680724"}},"outputId":"6e0f59dc-bbf8-41fd-de7d-ed918972f523"},"source":["DATA_PATH = \"/content/drive/MyDrive/deeplearningproject/Data/\"\n","imagePaths = list(paths.list_images(DATA_PATH))\n","\n","data = []\n","labels = []\n","\n","IMG_SIZE = 224\n","CHANNELS = 3\n","N_LABELS=2\n","\n","\n","# loop over the image paths\n","for imagePath in imagePaths:\n","\t# extract the class label from the filename\n","  label = imagePath.split(os.path.sep)[-2]\n","\t# load the input image (224x224) and preprocess it\n","  image = load_img(imagePath, target_size=(IMG_SIZE, IMG_SIZE))\n","  image = img_to_array(image)\n","  image = image/255\n","#image = preprocess_input(image)\n","\n","\t# update the data and labels lists, respectively\n","  data.append(image)\n","  labels.append(label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lO8uhHeWKXxG"},"source":["data = np.array(data, dtype=\"float32\")\n","labels = np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktkR5RtpKZ_G"},"source":["lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n","labels = to_categorical(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcJgNct0F6L6"},"source":["np.save('data',data)\n","np.save('labels',labels)"],"execution_count":null,"outputs":[]}]}
