{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1621545896419,
     "user": {
      "displayName": "Deep Team",
      "photoUrl": "",
      "userId": "13688180598913680724"
     },
     "user_tz": -180
    },
    "id": "qKMi2muZhyaN"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1541,
     "status": "ok",
     "timestamp": 1621545900070,
     "user": {
      "displayName": "Deep Team",
      "photoUrl": "",
      "userId": "13688180598913680724"
     },
     "user_tz": -180
    },
    "id": "E9MiTlXclMKs",
    "outputId": "26a26f10-ea69-4095-cd53-c7eb813b5cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1621545903880,
     "user": {
      "displayName": "Deep Team",
      "photoUrl": "",
      "userId": "13688180598913680724"
     },
     "user_tz": -180
    },
    "id": "D-85f7S9lTEs"
   },
   "outputs": [],
   "source": [
    "NUM_CLASS = 3\n",
    "head_model = base_model.output\n",
    "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(128, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(NUM_CLASS, activation=\"softmax\")(head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1621545907228,
     "user": {
      "displayName": "Deep Team",
      "photoUrl": "",
      "userId": "13688180598913680724"
     },
     "user_tz": -180
    },
    "id": "a34ItE5zlaMe"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1621545909224,
     "user": {
      "displayName": "Deep Team",
      "photoUrl": "",
      "userId": "13688180598913680724"
     },
     "user_tz": -180
    },
    "id": "Z-04udRZleky"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('C:/Users/hatce/OneDrive/Masaüstü/MFN/MFN_Model3.h5')\n",
    "\n",
    "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "source=cv2.VideoCapture(0)\n",
    "labels_dict={0:'Correct Mask',1:'Incorrect Mask',2:'No Mask'}\n",
    "color_dict={0:(0, 255, 0),1:(0, 255, 255),2:(0, 0, 255)}\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret,img=source.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    faces=face_clsfr.detectMultiScale(gray,1.3,5)  \n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "    \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(224,224))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,224,224,3))\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMaq71zOQYlveN7G3QjrA25",
   "collapsed_sections": [],
   "mount_file_id": "1NuDeAhXhrrB_DEWkx4rz5uoOCTMv-hLG",
   "name": "webcam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
